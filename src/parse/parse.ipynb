{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file and directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path('../../data')\n",
    "xmldir = datadir / 'raw'\n",
    "docdir = datadir / 'docs'\n",
    "\n",
    "xml_name = 'BILLS-116hjres31enr.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read the xml file \n",
    "\n",
    "The main body of the bill is in a tag called 'resolution-body',\n",
    "and is segregated into sections tagged 'division'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(xmldir / xml_name)\n",
    "tree = BeautifulSoup(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_body = tree.find('resolution-body')\n",
    "division = resolution_body.findAll('division')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the whole thing as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_text = resolution_body.get_text(' ', strip=True)\n",
    "file = open(xmldir / 'resolution-body.txt', 'w')\n",
    "file.write(mega_text)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214279"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_words = len(mega_text.split())\n",
    "raw_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to save a file\n",
    "\n",
    "Will replace with write to mongodb eventually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_docs = 0 \n",
    "n_words = 0 \n",
    "\n",
    "def save_doc(division, title, major, inter, small, body):\n",
    "    global n_docs, n_words\n",
    "    \n",
    "    headingfile = 'doc' + str(n_docs) + '.heading'\n",
    "    headingfile = docdir / headingfile\n",
    "    if headingfile.exists():\n",
    "        raise Exception('file already exists', headingfile)\n",
    "    \n",
    "    \n",
    "    contentsfile= 'doc' + str(n_docs) + '.body'\n",
    "    contentsfile = docdir / contentsfile\n",
    "    if contentsfile.exists():\n",
    "        raise Exception('file already exists', contentsfile)\n",
    "    \n",
    "    headings = dict(division=division, title=title, major=major, inter=inter, small=small)\n",
    "    file = open(headingfile, 'w')\n",
    "    json.dump(headings, file)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(contentsfile, 'w')\n",
    "    file.write(body)\n",
    "    file.close()\n",
    "    \n",
    "    n_docs += 1 \n",
    "    n_words += len(body.split())\n",
    "    \n",
    "    # print('---- Start doc --- ')\n",
    "    # print(major)\n",
    "    # print(inter)\n",
    "    # print(small)\n",
    "    # print(body)\n",
    "    # print('---- End doc --- ')\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the 'meat' of a node\n",
    "\n",
    "TODO: Do I want to replace parsable-cite tags? \n",
    "\n",
    "TODO: Do I want to strip all the enums?\n",
    "\n",
    "TODO: Do I want to do regex on dollar amounts here or later?\n",
    "\n",
    "TODO: Do this twice: once for preprocessed to save for reporting to user, plus once with the post-processed information for \n",
    "doing NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_header_text(node):\n",
    "    text = node.get_text(' ', strip=True)\n",
    "    header = node.find('header')\n",
    "    if header:\n",
    "        header = header.get_text(strip=True)\n",
    "        if text.find(header) == 0:\n",
    "            text = text.replace(header, '', 1)\n",
    "    elif node.name == 'section':\n",
    "        header = ''\n",
    "        enum = node.find('enum')\n",
    "        if enum:\n",
    "            enum = enum.get_text(strip=True)\n",
    "            if text.find(enum) == 0:\n",
    "                text = text.replace(enum, '', 1)\n",
    "    else:\n",
    "        header = ''\n",
    "                \n",
    "    return header, text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main walk the xml tree\n",
    "\n",
    "Goal is to put each chunk under a separate heading as it's own\n",
    "subdocument. There's a lot of twists and turns because the use \n",
    "of xml tags in different titles is not consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_title(division_name, t):\n",
    "    \n",
    "    title_name = t.find('header').string.strip()\n",
    "    # print(\"TITLE\", title_name)\n",
    "    \n",
    "    iterator = t.children\n",
    "    \n",
    "    kid = next(iterator, None)\n",
    "    next_kid = None\n",
    "    major_name = '' \n",
    "    inter_name = '' \n",
    "    small_name = ''\n",
    "    body = ''\n",
    "        \n",
    "    while kid != None:\n",
    "        if kid.name == 'appropriations-major':\n",
    "            major_name, text = extract_header_text(kid)\n",
    "            inter_name = ''\n",
    "            small_name = ''\n",
    "            if text != '':\n",
    "                # -- introductory material to the major section???\n",
    "                body = text\n",
    "                save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "                body = ''\n",
    "            \n",
    "        elif kid.name == 'appropriations-intermediate':\n",
    "            inter_name, text = extract_header_text(kid)\n",
    "            small_name = ''\n",
    "            \n",
    "            if len(text):\n",
    "                # -- must be a document??? \n",
    "                body = text\n",
    "                save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "                body = ''\n",
    "\n",
    "        elif kid.name == 'appropriations-small':\n",
    "            small_name, body = extract_header_text(kid)\n",
    "            header = kid.find('header')\n",
    "            if header == None and body != '':\n",
    "                # -- we REALLY wanted a header here... \n",
    "                # just shove this in a document and hope for the best!\n",
    "                save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "                body = ''\n",
    "            else:\n",
    "                # -- make sure body is complete\n",
    "                done = False\n",
    "                while not done:\n",
    "                    next_kid = next(iterator, None)\n",
    "                    # if there's no more to parse, we're done\n",
    "                    if next_kid == None: \n",
    "                        done = True\n",
    "                        if body != '': \n",
    "                            save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "                            body = ''\n",
    "                        small_name=''\n",
    "                        continue\n",
    "                        \n",
    "                    # body could be incomplete even if it ends with a period,\n",
    "                    # but these for sure we know we need to keep reading....\n",
    "                    incomplete_body = ((body == '') or (body[-1] != '.'))\n",
    "                        \n",
    "                    if next_kid.name == 'appropriations-small': \n",
    "                        subheader, sub_body = extract_header_text(next_kid)\n",
    "                        \n",
    "                        if len(sub_body) and (not len(subheader)):\n",
    "                            # we're still under the same heading, keep going\n",
    "                            body += ' ' + sub_body\n",
    "                            next_kid = None\n",
    "                        elif len(subheader) and incomplete_body:\n",
    "                            # we have subheadings with no text below\n",
    "                            small_name += ' ' + subheader\n",
    "                            if len(sub_body):\n",
    "                                body += ' ' + sub_body\n",
    "                            next_kid = None\n",
    "                        else:\n",
    "                            done = True\n",
    "                            save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "                            body = ''\n",
    "                            small_name=''\n",
    "                                \n",
    "                    elif (next_kid.name == 'section') and incomplete_body:\n",
    "                        _, more_text = extract_header_text(next_kid)\n",
    "                        body += ' ' + more_text\n",
    "                        next_kid = None\n",
    "                        \n",
    "                    elif not incomplete_body:\n",
    "                        done = True\n",
    "                        save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "                        assert(body[-1] == '.')\n",
    "                        body = '' \n",
    "                        small_name = ''\n",
    "                    \n",
    "        elif kid.name == 'section':\n",
    "            _, body = extract_header_text(kid)\n",
    "            save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "            body = ''\n",
    "                \n",
    "        if next_kid != None:\n",
    "            kid = next_kid # we peeked but didn't consume next_kid\n",
    "            next_kid = None\n",
    "        else:\n",
    "            kid = next(iterator, None)\n",
    "                \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in division:\n",
    "    name = d.find('header')\n",
    "    division_name = name.text.strip()\n",
    "    # print(\"DIVISION\", division_name)\n",
    "    \n",
    "    titles = d.findAll('title')\n",
    "    for t in titles:\n",
    "        read_title(division_name, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1111"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209133"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this isn't going to equal all the words in the doc at the\n",
    "# top of the file because I didn't count headers and I \n",
    "# tried to clean out some non-word counters and such \n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ../../data/docs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file and directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path('../../data')\n",
    "xmldir = datadir / 'raw'\n",
    "docdir = datadir / 'docs'\n",
    "\n",
    "xml_name = 'BILLS-116hjres31enr.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read the xml file \n",
    "\n",
    "The main body of the bill is in a tag called 'resolution-body',\n",
    "and is segregated into sections tagged 'division'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(xmldir / xml_name)\n",
    "tree = BeautifulSoup(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_body = tree.find('resolution-body')\n",
    "division = resolution_body.findAll('division')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the whole thing as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_text = \"\\n\".join([d.get_text('\\n', strip=True) for d in division])\n",
    "\n",
    "file = open(xmldir / 'resolution-body.txt', 'w')\n",
    "file.write(mega_text)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213696"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_words = len(mega_text.split())\n",
    "raw_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to save a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_docs = 0 \n",
    "n_words = 0 \n",
    "\n",
    "def save_doc(division, title, major, inter, small, body):\n",
    "    global n_docs, n_words\n",
    "    \n",
    "    headingfile = 'doc' + str(n_docs) + '.heading'\n",
    "    headingfile = docdir / headingfile\n",
    "    if headingfile.exists():\n",
    "        raise Exception('file already exists', headingfile)\n",
    "    \n",
    "    \n",
    "    contentsfile= 'doc' + str(n_docs) + '.body'\n",
    "    contentsfile = docdir / contentsfile\n",
    "    if contentsfile.exists():\n",
    "        raise Exception('file already exists', contentsfile)\n",
    "    \n",
    "    headings = dict(division=division, title=title, major=major, inter=inter, small=small)\n",
    "    file = open(headingfile, 'w')\n",
    "    json.dump(headings, file)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(contentsfile, 'w')\n",
    "    file.write(body)\n",
    "    file.close()\n",
    "    \n",
    "    n_docs += 1 \n",
    "    word_count = len(body.split())\n",
    "    n_words += word_count\n",
    "    \n",
    "    if word_count < 3:\n",
    "        pdb.set_trace()\n",
    "    \n",
    "    # print('---- Start doc --- ')\n",
    "    # print(major)\n",
    "    # print(inter)\n",
    "    # print(small)\n",
    "    # print(body)\n",
    "    # print('---- End doc --- ')\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main walk the xml tree\n",
    "\n",
    "Goal is to put each chunk under a separate heading as it's own\n",
    "subdocument. There's a lot of twists and turns because the use \n",
    "of xml tags in different titles is not consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ancestor_is_section(node):\n",
    "    if node.name == 'section':\n",
    "        return False\n",
    "    if ((node.name == 'header') and \n",
    "        (node.parent.name.find('appropriations') == 0) and \n",
    "        (node.parent.parent.name == 'section')):\n",
    "        return False\n",
    "    parent = node.parent\n",
    "    while (parent != None) and parent.name != 'title':\n",
    "        if parent.name == 'section':\n",
    "            return True\n",
    "        parent = parent.parent\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_title(division_name, t):\n",
    "    \n",
    "    headers_and_text = t.find_all(['section','header','text','continuation-text'])\n",
    "    \n",
    "    if headers_and_text[0].name != 'header':\n",
    "        pdb.set_trace()\n",
    "        \n",
    "    title_name = headers_and_text[0].get_text(strip=True)\n",
    "    # print(\"title_name = \", title_name)\n",
    "    \n",
    "    major_name = '' \n",
    "    inter_name = '' \n",
    "    small_name = ''\n",
    "    body = ''\n",
    "    finish_a_section = False\n",
    "    \n",
    "    for node in headers_and_text[1:]:\n",
    "        \n",
    "        if finish_a_section:\n",
    "            if ancestor_is_section(node):\n",
    "                continue\n",
    "            else:\n",
    "                finish_a_section = False\n",
    "            \n",
    "        if node.name == 'section':\n",
    "            finish_a_section = True\n",
    "            # finish whatever we had started -- \n",
    "            if body != '':\n",
    "                save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "                body = '' \n",
    "            \n",
    "                \n",
    "            for kid in node.children:\n",
    "                if kid.name != None:\n",
    "                    # checking for the header of the next section \n",
    "                    # nested under the current section\n",
    "                    if kid.name.find('appropriations') == 0:\n",
    "                        break\n",
    "                    else:\n",
    "                        body += kid.get_text(' ', strip=True)\n",
    "                \n",
    "            body = body.strip()\n",
    "            save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "            body = ''\n",
    "            \n",
    "        elif node.name == 'header':\n",
    "            \n",
    "            parent_name = node.parent.name\n",
    "            \n",
    "            if parent_name == 'appropriations-major':\n",
    "                # whenever there's a new major header, save the current body to the previous header\n",
    "                if body != '':\n",
    "                    if body[-1] != '.':\n",
    "                        pdb.set_trace()\n",
    "                    save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "                    body = '' \n",
    "                # finding a new major header means we're no longer under the previous\n",
    "                # intermediate or small header\n",
    "                major_name = node.get_text(' ', strip=True)\n",
    "                inter_name = ''\n",
    "                small_name = ''\n",
    "                \n",
    "            elif parent_name == 'appropriations-intermediate':\n",
    "                # whenever there's a new intermediate header, save the current body to the previous header\n",
    "                if body != '':\n",
    "                    if body[-1] != '.':\n",
    "                        pdb.set_trace()\n",
    "                    save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "                    body = '' \n",
    "                inter_name = node.get_text(' ', strip=True)\n",
    "                # new intermediate-level header means no longer under previous small heading\n",
    "                small_name = '' \n",
    "                \n",
    "            elif parent_name == 'appropriations-small':\n",
    "                if body != '':\n",
    "                    save_doc(division_name, title_name, major_name, inter_name, small_name, body)\n",
    "                    body = '' \n",
    "                    small_name = ''\n",
    "                    \n",
    "                if small_name == '':\n",
    "                    small_name = node.get_text(' ', strip=True)\n",
    "                else:\n",
    "                    small_name = ' '.join([small_name, node.get_text(' ', strip=True)])\n",
    "            else: \n",
    "                # -- we're in a subparagraph or subsection, not a new heading?\n",
    "                if node.previous_sibling.name != 'enum':\n",
    "                    pdb.set_trace()\n",
    "                    \n",
    "                if body == '':\n",
    "                    body = node.get_text(' ', strip=True)\n",
    "                else:\n",
    "                    body = \" \".join([body, node.get_text(' ', strip=True)])\n",
    "        else: # text or continuation-text\n",
    "            if body == '':\n",
    "                body = node.get_text(' ', strip=True)\n",
    "            else:\n",
    "                body = \" \".join([body, node.get_text(' ', strip=True)])\n",
    "            \n",
    "    # end of loop - save whatever body we were working on \n",
    "    if body != '':\n",
    "        save_doc(division_name, title_name, major_name, inter_name, small_name, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in division:\n",
    "    name = d.find('header')\n",
    "    division_name = name.get_text(strip=True)\n",
    "    # print(\"DIVISION\", division_name)\n",
    "    \n",
    "    titles = d.findAll('title')\n",
    "    for t in titles:\n",
    "        read_title(division_name, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207416"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this isn't going to equal all the words in the doc at the\n",
    "# top of the file because I didn't count headers and \n",
    "# there are a few places that are harder to parse\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
